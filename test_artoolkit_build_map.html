<html>

  <body>
  </body>

  <script type="text/javascript" src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
  <script src="artoolkit.min.js"></script>
  <script src="artoolkit.api.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/three.js/84/three.min.js"></script>


  <script type="text/javascript">

    // Globals

    var arController;
    var video;

    var renderer;
    var scene;
    var camera;
    var videoScene;
    var videoCamera;
    var cube;

    var bufferSize = 3;
    var ringBuffer = new Float32Array(16 * bufferSize);
    var ringIndex = 0;


    function setUpARController(video){
      arController = new ARController(video, 'camera_para.dat');
      arController.onload = function() {
        console.log('ARController ready for use', arController);
        setUpThreeJs();

        arController.setPatternDetectionMode( artoolkit.AR_MATRIX_CODE_DETECTION );

        tick();
      }
    }

    function setUpWebcam(){

      navigator.mediaDevices.enumerateDevices()
      .then(function(devices) {
        var id = 0;
        var fallbackId = 0;
        devices.forEach(function(device) {
          if (device.kind == "videoinput") {
            console.log(device)
            fallbackId = device.deviceId;
            if (device.label.search(/rear|back/) >= 0) {
              id = device.deviceId
              alert("using device: " + device.label)
            }
            if (id == 0) {
              id = fallbackId;
            }
          }
        });

        video = ARController.getUserMedia({
          //maxARVideoSize: 320, // do AR processing on scaled down video of this size
          maxARVideoSize: 180,
          video: {
            sourceId: id
          },
          onSuccess: function(video) {
            console.log('got video', video);
            setUpARController(video);

          }
        });
      });
    };

    function setUpThreeJs(){
      scene = new THREE.Scene();
      // fov is angle allowed, aspect is ration x gto y and near and far viewing plane
      // default position is z = 5
      //  camera is pointing down negative z axis
      // up is positive y - 3 is about limit of seeing at z = 0
      // right in positive x
      //camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 );

      camera = new THREE.Camera();
      camera.matrixAutoUpdate = false;
      camera.projectionMatrix.elements.set(arController.getCameraMatrix());
      //camera.scale.x = 0.5;
      scene.add(camera);

      console.log(camera.projectionMatrix)

      renderer = new THREE.WebGLRenderer({ antialias: true });
      //renderer.setSize(video.videoWidth, video.videoHeight);

      var aspectRatio = video.videoWidth/video.videoHeight

      var drawWidth = window.innerWidth;
      var drawHeight = Math.floor(window.innerWidth * aspectRatio);

      renderer.setSize(video.videoWidth, video.videoHeight);
      renderer.setPixelRatio(3);
      document.body.appendChild( renderer.domElement );

      var light = new THREE.PointLight(0xffffff);
      light.position.set(400, 500, 100);
      scene.add(light);
      var light = new THREE.PointLight(0xffffff);
      light.position.set(-400, -500, -100);
      scene.add(light);

      var geometry = new THREE.BoxGeometry( 1, 1, 1 );

      //var material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
      var material = new THREE.MeshLambertMaterial({ color: 0xffffff, wireframe: false })
      cube = new THREE.Mesh( geometry, material );
      console.log(cube);
      console.log(camera);
      //cube.matrixAutoUpdate = false;
      scene.add( cube );


      //camera.position.z = -5;




      // This was typo or changed pai in docs?
      var videoTex = new THREE.VideoTexture(video);

      videoTex.minFilter = THREE.LinearFilter;


      videoTex.flipY = false;

      var wv =1; //video.videoWidth;
      var hv =1; //video.videoHeight;
      var scaleFactor = 1;//wv/drawWidth
      var plane = new THREE.Mesh(
        new THREE.PlaneBufferGeometry(2, 2),  //2*wv/drawWidth / scaleFactor, 2*hv/drawHeight / scaleFactor),
        new THREE.MeshBasicMaterial({map: videoTex, side: THREE.DoubleSide})
      );


      plane.material.depthTest = false;
      plane.material.depthWrite = false;


      videoScene = new THREE.Scene();
      videoCamera = new THREE.OrthographicCamera(-1, 1, -1, 1, -1, 1);
      videoScene.add(videoCamera);
      videoScene.add(plane);

      // Set the renderer autoClear to false, otherwise it
      // clears the canvas before each render call.
      renderer.autoClear = false;
    }

    function tick(){
      requestAnimationFrame(tick);

      processTags();

      renderer.render( videoScene, videoCamera );


      renderer.render( scene, camera );

      cubes.map(function(cube){
        scene.remove(cube);
      })

      //	console.log(cube);


    }

var cubes = []
var captureRelationship = false;

    function drawCube(transform, color){
              var geometry = new THREE.BoxGeometry( 1, 1, 1 );
              var material = new THREE.MeshLambertMaterial({ color: color, wireframe: false })
              cube = new THREE.Mesh( geometry, material );
              var cubepos = new THREE.Matrix4()
              cubepos.elements.set(transform);
              cube.position.set( transform[12], transform[13], transform[14]);
              cube.setRotationFromMatrix(cubepos)
              cube.updateMatrix();
              cubes.push(cube)
              scene.add(cube);
    }


    var tagOrientations = {};
    tagOrientations[4] = new THREE.Matrix4()


    function processTags() {
      arController.detectMarker(video);

      var markerMatrix = new Float32Array(12);
      var glMatrix = new Float32Array(16);
      var minMatrix = new Float32Array(16);
      var minMatrixKnown = new Float32Array(16);

      var markers = arController.getMarkerNum();

      var minIndexUnknown = 1000;
      var minIndexKnown = 1000;

      for (var i=0; i < markers; i++) {
        var marker = arController.getMarker(i);

        if(marker.idMatrix > -1){
          arController.getTransMatSquare(i, 1 /* marker width */, markerMatrix);
          arController.transMatToGLMat(markerMatrix, glMatrix);

          if(tagOrientations[marker.idMatrix] == undefined){
            drawCube(glMatrix, 0xff0000);
            if(marker.idMatrix < minIndexUnknown){
              minIndexUnknown = marker.idMatrix;
              minMatrix.set(glMatrix);
            }

          }
          else{
            drawCube(glMatrix, 0x0000ff);
              if(marker.idMatrix < minIndexKnown){
                minIndexKnown = marker.idMatrix;
                minMatrixKnown.set(glMatrix);
            }
          }
          





        }
      }
      console.log(minIndexKnown);
      drawCube( minMatrix, 0x00ff00)
      drawCube( minMatrixKnown, 0xffff00)


      if(captureRelationship && minIndexUnknown < 1000 && minIndexKnown < 1000){
        var unKnownPos = new THREE.Matrix4();
        unKnownPos.elements.set(minMatrix);
        
        var knownPos = new THREE.Matrix4();
        knownPos.elements.set(minMatrixKnown);

        var relPos = new THREE.Matrix4();

        relPos.getInverse(knownPos);
        relPos.multiply(tagOrientations[minIndexKnown]);
        relPos.multiply(unKnownPos);

        var newPos = new THREE.Matrix4();

        newPos.getInverse(relPos);



        tagOrientations[minIndexUnknown] = newPos;



        captureRelationship = false;
      }
    }

    document.body.onkeyup = function(e){
      if(e.keyCode == 32){
        captureRelationship = true;

      }
    }


    setUpWebcam();


  </script>

</html>
